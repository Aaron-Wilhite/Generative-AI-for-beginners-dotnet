# Chat App Basics

In this lesson, we will explore the basics of building chat applications using Language Model Completions and Functions in .NET. We will also explore how to use Semantic Kernel and Microsoft Extensions AI (MEAI) to create chatbots and use Semantic Kernel to create plugins, or functionality that's called by the chatbot based on the user's input.

---

## Language model (LM) completions / chat

**INSERT: 5 min video .NET explanation, links to main GenAI and content**

As we saw in Chapter One, Language Models are a type of AI model that can generate text based on the input it receives.

This input can be a **prompt**, a **question**, or a **sentence**, and the model will generate a response based on the patterns it has learned from the data it was trained on.

Using Generative AI models helps to generate text that is coherent and contextually relevant. Hosting multiple models and auxiliating the system to be capable of open domain conversations.

This includes how to create the system message, how to interact with the user, and how to generate the response. The system message is the message that the system sends to the user to start the conversation. Being key for your User Experience, it should be clear and concise, and it should set the tone for the conversation. 

> üí° **Pro Tip**: Learn more about Language Models Completion and flow control in [Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners/tree/main/07-building-chat-applications/)

Tools, like those we presented in the first chapter, can be used in a multitude of scenarios, for example **Semantic Kernel**, and **Microsoft Extensions AI (MEAI)**.

**Semantic Kernel** is a .NET library that provides a simple API to interact with multiple language models and other AI services. It is designed to be easy to use and flexible, allowing you to build a wide range of applications that use AI.

The next picture will show the steps we follow in the creation of a chatbot using Semantic Kernel:

![Semantic Kernel](../03-CoreGenerativeAITechniques/images/skmaps.png)


Look at the following code snippet to implement a simple chatbot using Semantic Kernel and Azure OpenAI chat completion:

```csharp
// Create a kernel with Azure OpenAI chat completion service, using the model ID, endpoint, and API key
var builder = Kernel.CreateBuilder().AddAzureOpenAIChatCompletion(modelId, endpoint, apiKey);

// Add enterprise components, such as logging and telemetry
builder.Services.AddLogging(services => services.AddConsole().SetMinimumLevel(LogLevel.Trace));

// Build the kernel, which will allow you to interact with the multiple services and models
Kernel kernel = builder.Build();
var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();

// Add a plugin, this plugin allows us to easily add new functionality to the kernel. For example, this plugin adds a new command to the kernel that allows you to turn on and off the lights in your house.
kernel.Plugins.AddFromType<LightsPlugin>("Lights");

// Enable planning, which allows the kernel to plan and execute actions based on the user's input
OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new() 
{
    FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
};
```

To invoke the chatbot, you can use the following code snippet:

```csharp
// Create a history store the conversation, this will allow the chatbot to remember the context of the conversation and generate more relevant responses
var history = new ChatHistory();

// Initiate a back-and-forth chat on the console
string? userInput;
do {
    // Collect user input
    Console.Write("User > ");
    userInput = Console.ReadLine();

    // Add user input
    history.AddUserMessage(userInput);

    // Get the response from the AI, using the Azure OpenAI chat completion service, the chat history, the execution settings, and the kernel
    var result = await chatCompletionService.GetChatMessageContentAsync(
        history,
        executionSettings: openAIPromptExecutionSettings,
        kernel: kernel);

    // Print the results for the user
    Console.WriteLine("Assistant > " + result);

    // Add the message from the agent to the chat history store
    history.AddMessage(result.Role, result.Content ?? string.Empty);
} while (userInput is not null);
```	

> ‚ö†Ô∏è **Note**: Learn more about Semantic Kernel go to [the documentation for Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/get-started/quick-start-guide?pivots=programming-language-csharp)

For **MEAI**, the Microsoft Extensions AI (MEAI) is a .NET library that provides a simple API to interact with multiple language models and other AI services. It is designed to be easy to use and flexible, allowing you to build a wide range of applications that use AI.

Semantic Kernel uses to interact with .NET abstractions and services, for example providing interfaces for services like `IChatCompletionService` and `IPlugin`.

> ‚ö†Ô∏è **Note**: Learn more about MEAI go to [the documentation for MEAI](https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-ai-preview/)

On video, we can see how Bruno Capuano, a Cloud Advocate at Microsoft, explaing how can we use the demo at `src/BasicChat-01MEAI` and `src/BasicChat-02SemanticKernel` to create a chatbot using MEAI and Semantic Kernel. 

Lastly, take a look on **Ollama**, a coordinator between local models, cloud models and other AI services. It is designed to be easy to use and flexible, allowing you to build a wide range of applications that use AI. We can see how it can be used in the video at the start of the lesson.

Learn more about Ollama and it's integration with MEAI and Semantic Kernel in the video at the start of the lesson.

> ‚ö†Ô∏è **Note**: Learn more about Ollama go to [the documentation for Ollama](https://https://github.com/ollama/ollama/tree/main/docs)

## Functions and Plugins using LLMs

![Functions and Plugins using LLMs](../03-CoreGenerativeAITechniques/images/Functions.png)  

Exploring the concept of Functions and Plugins using LLMs, we can see how we can use the models to create a more complex system. Semantic Kernel and MEAI provide a way to create plugins that can be used to extend the functionality of the system.

Looking at the following code snippet, we can see how to call a plugin using Semantic Kernel:

```csharp
// Get the chat completions and create the calls for all adressable functions
    OpenAIPromptExecutionSettings openAIPromptExecutionSettings = new()
    {
        ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
    };
```

This code snippet shows how to create a plugin using Semantic Kernel, this plugin allows you to get the current temperature for a city, with the context of the conversation:

```csharp
public class CityTemperaturePlugIn
{
    [KernelFunction, Description("Returns the current temperature for a city.")]
    public async Task<string> GetCityTemperature(
        Kernel kernel,
        [Description("The city to check the temperature")] string city
    )
    {
        Console.WriteLine($"== FUNCTION CALL START ==");
        Console.WriteLine($"== City: {city}");

        var random = new Random();
        var temperature = random.Next(-10, 10);
        var message = $"The current temperature in {city} is {temperature} C";

        Console.WriteLine($"== Generated message: {message}");
        Console.WriteLine($"== FUNCTION CALL END ==");
        return message;
    }
}
```

> ‚ö†Ô∏è **Note**: Learn more about Functions and Plugins using LLMs go to [the documentation for Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-csharp)

---

Now, let's move to the next part of this lesson, where we will explore **Retriever-Augmented Generation** (RAG) and Multimedia AI approaches.

<p align="center">
    <a href="../03-CoreGenerativeAITechniques/02-rag-vision-audio.md">Go to Part 2 - RAG, Vision and Audio Applications</a>
</p>

---